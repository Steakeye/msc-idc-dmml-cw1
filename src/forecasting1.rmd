---
title: "Forecasting1"
output: html_document
---


```{r setup-f1, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r deps-f1, echo=FALSE, include=FALSE, message=FALSE}
mirrorUrl = "http://cran.ma.imperial.ac.uk"

# Install and load all packages up-front!
if(!require(readxl)) install.packages("readxl", repos = mirrorUrl)
if(!require(neuralnet)) install.packages("neuralnet", repos = mirrorUrl)
if(!require(Metrics)) install.packages("Metrics", repos = mirrorUrl)
if(!require(scales)) install.packages("scales", repos = mirrorUrl)
if(!require(data.table)) install.packages("data.table", repos = mirrorUrl)
#
library("readxl")
library("neuralnet")
library("Metrics")
library("scales")
library("data.table")

set.seed(1234)
```

<section>

#Question 3: Forecasting (MLP)

##Premise

>You need to construct an MLP neural network for this problem. You need to consider the appropriate input vector, as well as the internal network structure (hidden layers, nodes, learning rate). You may consider any de-trending scheme if you feel is necessary. Write a code in R Studio to address all these requirements. You need to show the performance of your network both graphically as well as in terms of usual statistical indices (MSE, RMSE and MAPE). Hint: Experiment with various network structures and show a comparison table of their performances. This will be a good justification for your final network choice. Show all your working steps. As everyone will have different forecasting result, emphasis in the marking scheme will be given to the adopted methodology and the explanation/justification of various decisions you have taken in order to provide an acceptable, in terms of performance, solution. The input selection problem is very important. Experiment with various options (i.e. how many past values you need to consider as potential network inputs).

<!--
3rd Objective (MLP)
• Discuss the input selection problem and propose various input configurations 10
• Design a number of MLPs, using various structures (layers/nodes) / input parameters and show in a table their performances comparison based on provided stat. indices 15
• Provide your best results both graphically (your prediction output vs. desired output) and via performance indices 5

resources:
-->

##Preparation of data

The exchange data needs to be loaded, partitioned, and scaled.

```{r prep-data-f1}
#going to import the Excel spreadsheet WhiteWine dataset
exchange.raw <- read_excel("../data/Exchange.xlsx")
```

Here's a glance at the dataset

```{r show-exchange-f1}
head(exchange.raw)
str(exchange.raw)
```

We want to scale the data to allow for faster training. 

```{r norm-func}
norm_func <- function(x){
     min_x <- min(x)

     return((x - min_x)/(max(x) - min_x))
} 
```
```{r scale-exchange-f1}
exchange.scaled <- exchange.raw

exchange.scaled[3] <- scale(exchange.scaled[3])

#Summary of scaled wine data
summary(exchange.scaled)
```
```{r normalise-exchange-f1}
exchange.normalised <- exchange.raw

exchange.normalised[3] <- norm_func(exchange.normalised[3])

#Summary of scaled wine data
summary(exchange.normalised)
```

And partition the data into a set for training and another for testing the neural network after.

```{r subset-exchange-f1}
exchange.scaled_train <- head(exchange.scaled, 320)
exchange.scaled_test <- tail(exchange.scaled, -320) #exchange.scaled[-1:-320, 1:3] #also works!


#Summary of scaled data
summary(exchange.scaled_train)
summary(exchange.scaled_test)
```
```{r subset-norm-exchange-f1}
exchange.normalised_train <- head(exchange.normalised, 320)
exchange.normalised_test <- tail(exchange.normalised, -320) #exchange.normalised[-1:-320, 1:3] #also works!


#Summary of normalised data
paste("training:")
summary(exchange.normalised_train)
paste("test:")
summary(exchange.normalised_test)
```

###Setting up the training data

Because we're looking to train the neural network on time-series data, we have to transform the data to make it easy to pass in time based input, which means we need to provide more than 1 input value at a time to train against the desired output; to that end, below is a code chunk that takes the exchange rate values and creates rows where the last entry is the desired output, the third is considered day 0 and the 1st to entries are 2 previous days from day 0.

Before the data is ready, a function can be created in order to re-use the functionality over and over; this way the same code can be applied to generating out test data as the training data.


```{r matrix-func-f1}
vector_to_time_series_data <- function(vec, colCount) {
  row_count <- length(vec)
  
  staggered_data_matrix <- matrix(vec, row_count, colCount)
  
  for (i in 1:row_count){
    new_row <- c(staggered_data_matrix[i])
    
    for (j in 1:(colCount-1)){
      new_row <- c(new_row, staggered_data_matrix[i + j])
    }
    
    staggered_data_matrix[i,] <- new_row
  }

  return (as.data.frame(head(staggered_data_matrix, row_count - (colCount -1))))
}
```

With this function we can transform the training currency values now: 
```{r matrix-exchange-f1}
staggered_data_frame <- vector_to_time_series_data(exchange.scaled_train$`USD/EUR`, 4)

colnames(staggered_data_frame) <- c("Input_dneg2", "Input_dneg1", "Input_d0", "Output")

#Summary of training data
head(staggered_data_frame)
```

##Creating & using the neural net

###Training the network

Now we have the data in a format such that we can provide 3 consecutive days as input and the following day as desired output, we are ready to train the neural network.

```{r train-mlp-f1}
mlp.form1 <- as.formula("Output ~ Input_d0 + Input_dneg1 + Input_dneg2")

mlp.nn1 <- neuralnet(mlp.form1, staggered_data_frame, hidden=c(8,4,2), threshold=0.01)
```

Now the neural network has been trained we can view a representation of its structure.

```{r display-mlp-f1}
plot(mlp.nn1)
```

###Testing the network

Before we can test the neural network against test data we need to transform the test data we took from the original dataset and transform it so we can pass in three input variables similarly to how the network was trained. Picking the number of inputs and what those inputs might be is part of the challenge of creating a neural network for time-series data; it's pretty obvious that one input value will hardly help project a future value but what value to pick isn't clear. The lower the number or inputs the greater likelihood of error but the higher the number of inputs, the increased complexity and longer training period.  I've picked 3 consecutive days to start with but will experiment with other configurations afterwards.

```{r prep-test-mlp-f1}
staggered_test_data_frame <- vector_to_time_series_data(exchange.scaled_test$`USD/EUR`, 3)
```

Now that the test data is arranged in the same way that the training data is, the neural network can be tested.

```{r make_comparison_table_func-f1}
expected_v_test_func <- function (expected, mlp_test) {
  expected_v_test <- cbind(expected, as.data.frame(head(mlp_test$net.result, -1)))
  colnames(expected_v_test) <- c("Expected Output", "Neural Net Output")
  return(expected_v_test)
}
```
```{r testing-mlp-f1}
mlp.nn1_results <- compute(mlp.nn1, staggered_test_data_frame)

test_expected_data.nn1 <- tail(exchange.scaled_test$`USD/EUR`, -3)

test_v_expected.nn1 <- expected_v_test_func(test_expected_data.nn1, mlp.nn1_results)
head(test_v_expected.nn1)
```

### Evaluating the predictions

There are two ways we can look at the quality of the performance of the neural network:
- Various single number values derived from the difference between the predicted and actual values
- Visualising the data, for example, by plotting the estimates and actual values on the same graph to more easily draw comparisons by eye.

#### Numeric indicators

And then the Sum of Square Errors, and Mean Squared Error values can be derived in order to look at the performance of the trained neural network against test data. The closer to 0 the values are, the better.

```{r indicator-funcs1-mlp-f1}
output_delta_func <- function (expected, actual) {
  return (c(expected-actual)) 
}
sse_func <- function(x) {
   return (sum( (x - mean(x) )^2 ))
}
mse_func <- function (x) {
  return(sse_func(x)/length(x))
}
```
```{r run-indicator-funcs1-mlp-f1}
test_delta.nn1 <- output_delta_func(test_v_expected.nn1$`Expected Output`, test_v_expected.nn1$`Neural Net Output`)
#SSE of this first nn
t_sse <- sse_func(test_delta.nn1)
t_sse
#MSE of this first nn
t_mse <- mse_func(test_delta.nn1)
t_mse

performance_scores <- list(nn1 = list(t_sse, t_mse))
```

Additionally we can look are the performance in terms of the Root Mean Square Error or the Mean Absolute Percentage Error. The Root Mean Square Error is the square root of the average of the squared errors, which allows for the greater individual errors to have a greater influence on the final error value. The Mean Absolute Percentage Error shows the error in terms of the the median of the errors as a fraction of the estimated value, which is displayed as a percentage; the biggest drawback to this measure is the risk of dividing by 0 is the estimated value is 0 but is doesn't allow the biggest deltas to influence the final value more than by their proportions.

What follows are the RMSE and MAPE values for the neural net.

```{r run-indicator2-mlp-f1}
#RMSE for the nn
t_rmse <- rmse(test_v_expected.nn1$`Neural Net Output`, test_v_expected.nn1$`Expected Output`)
t_rmse
#MAPE for the nn
t_mape <- percent(mape(test_v_expected.nn1$`Neural Net Output`, test_v_expected.nn1$`Expected Output`))
t_mape

performance_scores$nn1 <- append(performance_scores$nn1, c(t_rmse, t_mape))
```

#### Visual evaluation

That follows is a graph plotting neural net predicted values against actual values.


```{r line-graph-func-mlp-f1}
line_compare_nn_to_actual <- function (compare_data, token_x) {
  count.col <- ncol(compare_data)

  # get the range for the x and y axis 
  plot_range.y <- range(compare_data)
  plot_range.x <- range(1:nrow(compare_data))
  
  #print(c("plot_range.y:",  plot_range.y, " - "))
  #print(c("compare_data:",  compare_data, " - "))
  
  # set up the plot 
  plot(token_x, type="n", xlab="Days", ylab="Normalised Exchange Rate") 
  
  colors <- c(6, 4)
  linetype <- c(1:count.col) 
  plotchar <- seq(1, 0)
  
  # add lines 
  for (i in 1:count.col) { 
    lines(test_v_expected.nn1[i], type="b", lwd=1.5,
      lty=linetype[i], col=colors[i], pch=plotchar[i]) 
  } 
  
  # add a title and subtitle 
  title("Exchange Rate Prediction Versus Actual", "Comparing actual values for USD/EUR rates against values derived from a Neural Network")
  
  return(list(linetype, plotchar, colors))
}
```
```{r line-graph-mlp-f1}
# Create Line Chart
linetypes <- line_compare_nn_to_actual(test_v_expected.nn1, test_v_expected.nn1$`Expected Output`)

# add a legend 
legend(45, -.25, names(test_v_expected.nn1), cex=0.8, col=linetypes[[3]], pch=linetypes[[2]], lty=linetypes[[1]], title="Exchange Rates")
```

What's interesting about looking at it visually, is how it's more obvious from this perspective than it is from indicators values, that the neural net predictions are similar overall but with a latency of a few days; this isn't very useful for forecasting and might actually suggest a kind of over-fitting, where the network has been too tightly trained with the training data. I'm not certain that this is the case however because this graph is based on data that was not used for training purpose.

## Experimenting with other Neural Network configurations

Now that we have one neural net with performance results, it's time to use this as a benchmark/baseline and create other neural networks to see if we can improve on performance.

### Normalised data instead of scaled data

I'm just curious as to whether or not normalising the data between 0 and 1 would work better than between -1 and 1 around a mean of 0.

```{r matrix-exchange-normalised-f1}
normalised_staggered_data_frame <- vector_to_time_series_data(exchange.normalised_train$`USD/EUR`, 4)

colnames(normalised_staggered_data_frame) <- c("Input_dneg2", "Input_dneg1", "Input_d0", "Output")

#Summary of training data
head(normalised_staggered_data_frame)
```
```{r train-mlp-norm-f1}
mlp.form1 <- as.formula("Output ~ Input_d0 + Input_dneg1 + Input_dneg2")
mlp.nn1 <- neuralnet(mlp.form1, staggered_data_frame, hidden = c(8,4,2), threshold=0.01)

mlp.nn1_norm <- neuralnet(mlp.form1, normalised_staggered_data_frame, hidden=c(8,4,2), threshold=0.01)
```

```{r display-mlp-norm-f1}
plot(mlp.nn1_norm)
```

```{r prep-test-mlp-norm-f1}
normalised_staggered_test_data_frame <- vector_to_time_series_data(exchange.normalised_test$`USD/EUR`, 3)

colnames(normalised_staggered_test_data_frame) <- c("Input_dneg2", "Input_dneg1", "Input_d0")

#Summary of training data
head(normalised_staggered_test_data_frame)
```

```{r testing-mlp-norm-f1}
mlp.nn1_norm_results <- compute(mlp.nn1_norm, normalised_staggered_test_data_frame)

test_expected_data.nn1_norm <- tail(exchange.normalised_test$`USD/EUR`, -3)

test_v_expected.nn1_norm <- expected_v_test_func(test_expected_data.nn1_norm, mlp.nn1_norm_results)
head(test_v_expected.nn1_norm)
```
```{r run-indicator-funcs1-mlp-norm-f1}
test_delta.nn1_norm <- output_delta_func(test_v_expected.nn1_norm$`Expected Output`, test_v_expected.nn1_norm$`Neural Net Output`)
#SSE of this first nn
t_sse <- sse_func(test_delta.nn1_norm)
t_sse
#MSE of this first nn
t_mse <- mse_func(test_delta.nn1_norm)
t_mse
#RMSE for the nn
t_rmse <- rmse(test_v_expected.nn1_norm$`Neural Net Output`, test_v_expected.nn1_norm$`Expected Output`)
t_rmse
#MAPE for the nn
t_mape <- percent(mape(test_v_expected.nn1_norm$`Neural Net Output`, test_v_expected.nn1_norm$`Expected Output`))
t_mape

performance_scores <- append(performance_scores, list(nn1_norm = list(t_sse, t_mse, t_rmse, t_mape)))

```
```{r line-graph-mlp-norm-f1}
# Create Line Chart
linetypes <- line_compare_nn_to_actual(test_v_expected.nn1_norm, test_v_expected.nn1_norm$`Expected Output`)

# add a legend 
legend(0, .75, names(test_v_expected.nn1_norm), cex=0.8, col=linetypes[[3]], pch=linetypes[[2]], lty=linetypes[[1]], title="Exchange Rates")
```

I'm not really sure what's going on with the line graph being plot for this but the figures show that the use of normalised data over scaled data is a marked improvement; the number of steps to train the netowrk is faster, the accuracy is higher against test data; as such, I will make sure all other nueral networks for this experiment will use the normalised data.

### Alternative hidden layer structures

The hidden layers are the 'secret sauce' of this kind of neural network, the layers describe neurons consisting of nodes and vertices that connect to other neuron nodes; the vertices between nodes adjust the values as they are passed from node to node resulting in the answer at the end of the chain off layers. The first neural network had 3 hidden layers each powers of 2, starting with 8 and halving at each next layer.

The next step is to experiment with the same dataset and the same input values but experiment with the accuracy of some different hinder layer structures like:

1. 6, 9, 6
2. 6, 9, 6, 3
3. 12, 8, 4
4. 16, 9, 4

### {6, 9, 6} hidden layer structure

```{r train-mlp-6-9-6-f1}
#mlp.form1 <- as.formula("Output ~ Input_d0 + Input_dneg1 + Input_dneg2")

mlp.nn_6_9_6 <- neuralnet(mlp.form1, normalised_staggered_data_frame, hidden = c(6, 9, 6), threshold=0.05, stepmax = 800000)
```
```{r display-mlp-6-9-6-f1}
plot(mlp.nn_6_9_6)
```

```{r comparison-table-mlp-6-9-6-f1}
mlp.nn2_results <- compute(mlp.nn_6_9_6, normalised_staggered_test_data_frame)

test_expected_data.nn2 <- tail(exchange.normalised_test$`USD/EUR`, -3)

test_v_expected.nn2 <- expected_v_test_func(test_expected_data.nn2, mlp.nn2_results)
```
```{r run-indicator-funcs-mlp-6-9-6-f1}
test_delta.nn2 <- output_delta_func(test_v_expected.nn2$`Expected Output`, test_v_expected.nn2$`Neural Net Output`)
#SSE of this first nn
t_sse <- sse_func(test_delta.nn2)
t_sse
#MSE of this first nn
t_mse <- mse_func(test_delta.nn2)
t_mse
#RMSE for the nn
t_rmse <- rmse(test_v_expected.nn2$`Neural Net Output`, test_v_expected.nn2$`Expected Output`)
t_rmse
#MAPE for the nn
t_mape <- percent(mape(test_v_expected.nn2$`Neural Net Output`, test_v_expected.nn2$`Expected Output`))
t_mape

performance_scores <- append(performance_scores, list(nn2 = list(t_sse, t_mse, t_rmse, t_mape)))

```

```{r line-graph-mlp-6-9-6-f1}
# Create Line Chart
linetypes <- line_compare_nn_to_actual(test_v_expected.nn2, test_v_expected.nn2$`Expected Output`)

# add a legend 
legend(0, .75, names(test_v_expected.nn2), cex=0.8, col=linetypes[[3]], pch=linetypes[[2]], lty=linetypes[[1]], title="Exchange Rates")
```

### {6, 9, 6, 3} hidden layer structure

```{r train-mlp-6-9-6-3-f1}
#mlp.form1 <- as.formula("Output ~ Input_d0 + Input_dneg1 + Input_dneg2")

mlp.nn_6_9_6_3 <- neuralnet(mlp.form1, normalised_staggered_data_frame, hidden = c(6, 9, 6, 3), threshold=0.05, stepmax = 1200000)
```
```{r display-mlp-6-9-6-3-f1}
plot(mlp.nn_6_9_6_3)
```

```{r comparison-table-mlp-6-9-6-3-f1}
mlp.nn3_results <- compute(mlp.nn_6_9_6_3, normalised_staggered_test_data_frame)

test_expected_data.nn3 <- tail(exchange.normalised_test$`USD/EUR`, -3)

test_v_expected.nn3 <- expected_v_test_func(test_expected_data.nn3, mlp.nn3_results)
```
```{r run-indicator-funcs-mlp-6-9-6-3-f1}
test_delta.nn3 <- output_delta_func(test_v_expected.nn3$`Expected Output`, test_v_expected.nn3$`Neural Net Output`)
#SSE of this first nn
t_sse <- sse_func(test_delta.nn3)
t_sse
#MSE of this first nn
t_mse <- mse_func(test_delta.nn3)
t_mse
#RMSE for the nn
t_rmse <- rmse(test_v_expected.nn3$`Neural Net Output`, test_v_expected.nn3$`Expected Output`)
t_rmse
#MAPE for the nn
t_mape <- percent(mape(test_v_expected.nn3$`Neural Net Output`, test_v_expected.nn3$`Expected Output`))
t_mape

performance_scores <- append(performance_scores, list(nn3 = list(t_sse, t_mse, t_rmse, t_mape)))

```

```{r line-graph-mlp-6-9-6-3-f1}
# Create Line Chart
linetypes <- line_compare_nn_to_actual(test_v_expected.nn3, test_v_expected.nn3$`Expected Output`)

# add a legend 
legend(0, .75, names(test_v_expected.nn3), cex=0.8, col=linetypes[[3]], pch=linetypes[[2]], lty=linetypes[[1]], title="Exchange Rates")
```


### {12, 8, 4} hidden layer structure

```{r train-mlp-12-8-4-f1}
#mlp.form1 <- as.formula("Output ~ Input_d0 + Input_dneg1 + Input_dneg2")

mlp.nn_12_8_4 <- neuralnet(mlp.form1, normalised_staggered_data_frame, hidden = c(12, 8, 4), threshold=0.05, stepmax = 1200000)
```
```{r display-mlp-12-8-4-f1}
plot(mlp.nn_12_8_4)
```

```{r comparison-table-mlp-mlp.nn-12-8-4-f1}
mlp.nn4_results <- compute(mlp.nn_12_8_4, normalised_staggered_test_data_frame)

test_expected_data.nn4 <- tail(exchange.normalised_test$`USD/EUR`, -3)

test_v_expected.nn4 <- expected_v_test_func(test_expected_data.nn4, mlp.nn4_results)
```
```{r run-indicator-funcs-mlp-12-8-4-f1}
test_delta.nn4 <- output_delta_func(test_v_expected.nn4$`Expected Output`, test_v_expected.nn4$`Neural Net Output`)
#SSE of this first nn
t_sse <- sse_func(test_delta.nn4)
t_sse
#MSE of this first nn
t_mse <- mse_func(test_delta.nn4)
t_mse
#RMSE for the nn
t_rmse <- rmse(test_v_expected.nn4$`Neural Net Output`, test_v_expected.nn4$`Expected Output`)
t_rmse
#MAPE for the nn
t_mape <- percent(mape(test_v_expected.nn4$`Neural Net Output`, test_v_expected.nn4$`Expected Output`))
t_mape

performance_scores <- append(performance_scores, list(nn4 = list(t_sse, t_mse, t_rmse, t_mape)))

```

```{r line-graph-mlp-12-8-4-f1}
# Create Line Chart
linetypes <- line_compare_nn_to_actual(test_v_expected.nn4, test_v_expected.nn4$`Expected Output`)

# add a legend 
legend(0, .75, names(test_v_expected.nn4), cex=0.8, col=linetypes[[3]], pch=linetypes[[2]], lty=linetypes[[1]], title="Exchange Rates")
```

### {16, 9, 4} hidden layer structure

```{r train-mlp-16-9-4-f1}
#mlp.form1 <- as.formula("Output ~ Input_d0 + Input_dneg1 + Input_dneg2")

mlp.nn_16_9_4 <- neuralnet(mlp.form1, normalised_staggered_data_frame, hidden = c(16, 9, 4), threshold=0.05, stepmax = 1200000)
```

```{r display-mlp-16-9-4-f1}
plot(mlp.nn_16_9_4)
```

```{r comparison-table-mlp-mlp.nn-16-9-4-f1}
mlp.nn5_results <- compute(mlp.nn_16_9_4, normalised_staggered_test_data_frame)

test_expected_data.nn5 <- tail(exchange.normalised_test$`USD/EUR`, -3)

test_v_expected.nn5 <- expected_v_test_func(test_expected_data.nn5, mlp.nn5_results)
```
```{r run-indicator-funcs-mlp-16-9-4-f1}
test_delta.nn5 <- output_delta_func(test_v_expected.nn5$`Expected Output`, test_v_expected.nn5$`Neural Net Output`)
#SSE of this first nn
t_sse <- sse_func(test_delta.nn5)
t_sse
#MSE of this first nn
t_mse <- mse_func(test_delta.nn5)
t_mse
#RMSE for the nn
t_rmse <- rmse(test_v_expected.nn5$`Neural Net Output`, test_v_expected.nn5$`Expected Output`)
t_rmse
#MAPE for the nn
t_mape <- percent(mape(test_v_expected.nn5$`Neural Net Output`, test_v_expected.nn5$`Expected Output`))
t_mape

performance_scores <- append(performance_scores, list(nn5 = list(t_sse, t_mse, t_rmse, t_mape)))
```

```{r line-graph-mlp-16-9-4-f1}
# Create Line Chart
linetypes <- line_compare_nn_to_actual(test_v_expected.nn5, test_v_expected.nn5$`Expected Output`)

# add a legend 
legend(0, .75, names(test_v_expected.nn5), cex=0.8, col=linetypes[[3]], pch=linetypes[[2]], lty=linetypes[[1]], title="Exchange Rates")
```

### Performance Thus Far
```{r performance-mlp-structures}
# Display a table for performance so far
perf_dt_1 <- rbindlist(performance_scores)
perf_dt_1 <- cbind(names(performance_scores), perf_dt_1)
colnames(perf_dt_1) <- c("NN", "SSE", "MSE", "RMSE", "MAPE")
perf_dt_1
```

Looking at the performnce metrics so far, it would make sense to invest more time experimenting with neural networks with the following hidden layers: {6, 9, 6} (nn2), {12, 8, 4} (nn4); for these two structures, all the metrics outperorm the other neural networks in terms of being closest to 0. What needs to be seen now is whether of not the accuracy of the netowrks can be improved by increasing or decreasing the number of inputs. It would make sense that accuracy should increase with greater number of inputs but for the same ok completeness, 2 inputs will be tried as well as 4.

##Alternative Input Counts

In order to eperiment with the imputs we need to first prepare the data.

### Preparing the data for 2 inputs
```{r matrix-exchange-normalised-2i-f1}
normalised_staggered_2i_data_frame <- vector_to_time_series_data(exchange.normalised_train$`USD/EUR`, 3)

colnames(normalised_staggered_2i_data_frame) <- c("Input_dneg1", "Input_d0", "Output")

#Summary of training data
head(normalised_staggered_2i_data_frame)
```
```{r prep-test-mlp-norm-2i-f1}
normalised_staggered_2i_test_data_frame <- vector_to_time_series_data(exchange.normalised_test$`USD/EUR`, 2)

colnames(normalised_staggered_2i_test_data_frame) <- c("Input_dneg1", "Input_d0")

#Summary of training data
head(normalised_staggered_2i_test_data_frame)
```

### Preparing the data for 4 inputs
```{r matrix-exchange-normalised-4i-f1}
normalised_staggered_4i_data_frame <- vector_to_time_series_data(exchange.normalised_train$`USD/EUR`, 5)

colnames(normalised_staggered_4i_data_frame) <- c("Input_dneg3", "Input_dneg2", "Input_dneg1", "Input_d0", "Output")

#Summary of training data
head(normalised_staggered_4i_data_frame)
```
```{r prep-test-mlp-norm-4i-f1}
normalised_staggered_4i_test_data_frame <- vector_to_time_series_data(exchange.normalised_test$`USD/EUR`, 4)

colnames(normalised_staggered_4i_test_data_frame) <- c("Input_dneg3", "Input_dneg2", "Input_dneg1", "Input_d0")

#Summary of training data
head(normalised_staggered_4i_test_data_frame)
```

### {6, 9, 6} hidden layer structure with 2 inputs

```{r train-mlp-2i-6-9-6-f1}
mlp.form2 <- as.formula("Output ~ Input_d0 + Input_dneg1")

mlp.nn_6_9_6_2i <- neuralnet(mlp.form2, normalised_staggered_2i_data_frame, hidden = c(6, 9, 6), threshold=0.05, stepmax = 800000)
```
```{r display-mlp-2i-6-9-6-f1}
plot(mlp.nn_6_9_6_2i)
```

```{r comparison-table-mlp-2i-6-9-6-f1}
mlp.nn2_2i_results <- compute(mlp.nn_6_9_6_2i, normalised_staggered_2i_test_data_frame)

test_expected_data.nn2_2i <- tail(exchange.normalised_test$`USD/EUR`, -2)

test_v_expected.nn2_2i <- expected_v_test_func(test_expected_data.nn2_2i, mlp.nn2_2i_results)
```
```{r run-indicator-funcs-mlp-2i-6-9-6-f1}
test_delta.nn2_2i <- output_delta_func(test_v_expected.nn2_2i$`Expected Output`, test_v_expected.nn2_2i$`Neural Net Output`)
#SSE of this first nn
t_sse <- sse_func(test_delta.nn2_2i)
t_sse
#MSE of this first nn
t_mse <- mse_func(test_delta.nn2_2i)
t_mse
#RMSE for the nn
t_rmse <- rmse(test_v_expected.nn2_2i$`Neural Net Output`, test_v_expected.nn2_2i$`Expected Output`)
t_rmse
#MAPE for the nn
t_mape <- percent(mape(test_v_expected.nn2_2i$`Neural Net Output`, test_v_expected.nn2_2i$`Expected Output`))
t_mape

performance_scores <- append(performance_scores, list(nn2_2i = list(t_sse, t_mse, t_rmse, t_mape)))

```

```{r line-graph-mlp-2i-6-9-6-f1}
# Create Line Chart
linetypes <- line_compare_nn_to_actual(test_v_expected.nn2_2i, test_v_expected.nn2_2i$`Expected Output`)

# add a legend 
legend(0, .75, names(test_v_expected.nn2_2i), cex=0.8, col=linetypes[[3]], pch=linetypes[[2]], lty=linetypes[[1]], title="Exchange Rates")
```


### {6, 9, 6} hidden layer structure with 4 inputs

```{r train-mlp-4i-6-9-6-f1}
mlp.form4 <- as.formula("Output ~ Input_d0 + Input_dneg1 + Input_dneg2 + Input_dneg3")

mlp.nn_6_9_6_4i <- neuralnet(mlp.form4, normalised_staggered_4i_data_frame, hidden = c(6, 9, 6), threshold=0.05, stepmax = 800000)
```
```{r display-mlp-4i-6-9-6-f1}
plot(mlp.nn_6_9_6_4i)
```

```{r comparison-table-mlp-4i-6-9-6-f1}
mlp.nn2_4i_results <- compute(mlp.nn_6_9_6_4i, normalised_staggered_4i_test_data_frame)

test_expected_data.nn2_4i <- tail(exchange.normalised_test$`USD/EUR`, -4)

test_v_expected.nn2_4i <- expected_v_test_func(test_expected_data.nn2_4i, mlp.nn2_4i_results)
```
```{r run-indicator-funcs-mlp-4i-6-9-6-f1}
test_delta.nn2_4i <- output_delta_func(test_v_expected.nn2_4i$`Expected Output`, test_v_expected.nn2_4i$`Neural Net Output`)
#SSE of this first nn
t_sse <- sse_func(test_delta.nn2_4i)
t_sse
#MSE of this first nn
t_mse <- mse_func(test_delta.nn2_4i)
t_mse
#RMSE for the nn
t_rmse <- rmse(test_v_expected.nn2_4i$`Neural Net Output`, test_v_expected.nn2_4i$`Expected Output`)
t_rmse
#MAPE for the nn
t_mape <- percent(mape(test_v_expected.nn2_4i$`Neural Net Output`, test_v_expected.nn2_4i$`Expected Output`))
t_mape

performance_scores <- append(performance_scores, list(nn2_4i = list(t_sse, t_mse, t_rmse, t_mape)))

```

```{r line-graph-mlp-4i-6-9-6-f1}
# Create Line Chart
linetypes <- line_compare_nn_to_actual(test_v_expected.nn2_4i, test_v_expected.nn2_4i$`Expected Output`)

# add a legend 
legend(0, .75, names(test_v_expected.nn2_4i), cex=0.8, col=linetypes[[3]], pch=linetypes[[2]], lty=linetypes[[1]], title="Exchange Rates")
```

### Performance After Input Experimentation
```{r performance-mlp-structures}
# Display a table for performance so far
perf_dt_2 <- rbindlist(performance_scores)
perf_dt_2 <- cbind(names(performance_scores), perf_dt_2)
colnames(perf_dt_2) <- c("NN", "SSE", "MSE", "RMSE", "MAPE")
perf_dt_2
```
## Conclusion

...


</section>
